{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6dac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013d50ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                       0\n",
      "32     https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/namibia-vs-united-arab-emirates-10th-match-first-round-group-a-1298144/full-scorecard\n",
      "33             https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/netherlands-vs-sri-lanka-9th-match-first-round-group-a-1298143/full-scorecard\n",
      "34              https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/west-indies-vs-zimbabwe-8th-match-first-round-group-b-1298142/full-scorecard\n",
      "35                  https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/ireland-vs-scotland-7th-match-first-round-group-b-1298141/full-scorecard\n",
      "36    https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/sri-lanka-vs-united-arab-emirates-6th-match-first-round-group-a-1298140/full-scorecard\n",
      "37               https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/namibia-vs-netherlands-5th-match-first-round-group-a-1298139/full-scorecard\n",
      "38                  https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/ireland-vs-zimbabwe-4th-match-first-round-group-b-1298138/full-scorecard\n",
      "39              https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/scotland-vs-west-indies-3rd-match-first-round-group-b-1298137/full-scorecard\n",
      "40  https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/netherlands-vs-united-arab-emirates-2nd-match-first-round-group-a-1298136/full-scorecard\n",
      "41                 https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2022-23-1298134/namibia-vs-sri-lanka-1st-match-first-round-group-a-1298135/full-scorecard\n"
     ]
    }
   ],
   "source": [
    "# get the individual team match URLs which will be used below to get individual player links\n",
    "URL_tournament = \"https://www.espncricinfo.com/records/tournament/team-match-results/icc-men-s-t20-world-cup-2022-23-14450\"\n",
    "header = ({'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36', 'Accept-Language' : 'eng-US'\n",
    "            })\n",
    "webpage = requests.get(URL_tournament, headers=header)\n",
    "#print(URL_tournament)\n",
    "\n",
    "# print(webpage.content)\n",
    "\n",
    "# the text to be added to the href contained in the table\n",
    "\n",
    "URL_to_be_added = 'https://www.espncricinfo.com'\n",
    "\n",
    "# store the URLs extraxted into a list\n",
    "\n",
    "URL_list = []\n",
    "\n",
    "soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "\n",
    "# the tournament details are in the table with class ds-table \n",
    "table_tournament = soup.find('table', class_ = 'ds-table')\n",
    "# read all the rows of the table\n",
    "rows = table_tournament.find_all('tr')\n",
    "\n",
    "\n",
    "# ------------------get the href from the last column of each row----------------\n",
    "\n",
    " # Find all the rows in the table\n",
    "for row in rows:\n",
    "    # Find the last cell in each row\n",
    "    cells = row.find_all('td')\n",
    "    last_cell = cells[-1]\n",
    "\n",
    "# Find the <a> element within the last cell\n",
    "    link = last_cell.find('a')\n",
    "\n",
    "    if link and link.has_attr('href'):\n",
    "# Extract and print the href attribute\n",
    "        href = link['href']\n",
    "        URL_list.append(URL_to_be_added+href)\n",
    "        #print(URL_to_be_added+href)\n",
    "# convert the list to a df\n",
    "URL_df = pd.DataFrame(URL_list)\n",
    "\n",
    "# Adjust the maximum column width to show the entire text\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "print(URL_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b844e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below clicks on each individual player name in the match and gets the links\n",
    "\n",
    "# Initialize a list to store the table data\n",
    "\n",
    "first_innings_batting_table = []\n",
    "first_innings_bowling_table = []\n",
    "second_innings_batting_table = []\n",
    "second_innings_bowling_table = []\n",
    "\n",
    "fi_batting_links = []\n",
    "fi_bowling_links = []\n",
    "si_batting_links = []\n",
    "si_bowling_links = []\n",
    "\n",
    "# counter to count all links\n",
    "i=0\n",
    "\n",
    "# counter to iterate through rows\n",
    "j=1\n",
    "\n",
    "# counter to iterate over the tables in the page - there are 4 of them \n",
    "# two for the first innings:  bowling and batting and 2 for second innings:  bowling and batting\n",
    "l_df = len(URL_df)\n",
    "# l_df = 1\n",
    "\n",
    "# the text to be added to the URL - https://www.espncricinfo.com/\n",
    "URL_to_added = 'https://www.espncricinfo.com'\n",
    "\n",
    "while(i<l_df):\n",
    "\n",
    "    URL = URL_df.iloc[i,0]\n",
    "#     print(URL)\n",
    "# header is required as the server from where we are getting data needs to think \n",
    "# it is coming from a real person and not a bot\n",
    "    header = ({'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36', 'Accept-Language' : 'eng-US'\n",
    "                })\n",
    "    webpage = requests.get(URL, headers=header)\n",
    "# parse the webpage\n",
    "    fi_si_soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "    \n",
    "# store the tables in a variable\n",
    "    fi_si_tables = fi_si_soup.find_all('table')\n",
    "\n",
    "# the tables of batting and bowling are assigned to the empty lists created above\n",
    "    first_innings_batting_table = fi_si_tables[0]\n",
    "    first_innings_bowling_table = fi_si_tables[1]\n",
    "    second_innings_batting_table = fi_si_tables[2]\n",
    "    second_innings_bowling_table = fi_si_tables[3]\n",
    "    \n",
    "# find all the rows in each table above and assign them\n",
    "    fi_batting_table_rows = first_innings_batting_table.find_all(\"tr\",  class_=\"\")\n",
    "    fi_bowling_table_rows = first_innings_bowling_table.find_all(\"tr\",  class_=\"\")\n",
    "    si_batting_table_rows = second_innings_batting_table.find_all(\"tr\",  class_=\"\")\n",
    "    si_bowling_table_rows = second_innings_bowling_table.find_all(\"tr\",  class_=\"\")\n",
    "    \n",
    "# for each table rows do the below\n",
    "# Iterate over the table rows and print their text content - first batting\n",
    "# the steps are same for fi and si batting and bowling\n",
    "    for fi_batting_table_row in fi_batting_table_rows:\n",
    "        \n",
    "# Find the anchor tag within the table row\n",
    "        fi_batting_anchor_tag = fi_batting_table_row.find(\"a\")\n",
    "    \n",
    "# if the anchor tag exists put theat into a list\n",
    "        if fi_batting_anchor_tag:\n",
    "            \n",
    "# Get the href attribute from the anchor tag\n",
    "            fi_batting_href = fi_batting_anchor_tag[\"href\"]\n",
    "    \n",
    "# put the link in a list\n",
    "            fi_batting_links.append(URL_to_added+fi_batting_href)\n",
    "            \n",
    "# if anchor row is not present skip and go to the next row            \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    for fi_bolwing_table_row in fi_bowling_table_rows:\n",
    "        # Find the anchor tag within the table row\n",
    "        fi_bolwing_anchor_tag = fi_bolwing_table_row.find(\"a\")\n",
    "        if fi_bolwing_anchor_tag:\n",
    "            \n",
    "            # Get the href attribute from the anchor tag\n",
    "            fi_bolwing_href = fi_bolwing_anchor_tag[\"href\"]\n",
    "            # put the link in a list\n",
    "            fi_bowling_links.append(URL_to_added+fi_bolwing_href)\n",
    "            # Print the href\n",
    "            #print(fi_bowling_links)\n",
    "        else:\n",
    "            continue\n",
    "#         print(table_row.text)\n",
    "    for si_batting_table_row in si_batting_table_rows:\n",
    "        # Find the anchor tag within the table row\n",
    "        si_batting_anchor_tag = si_batting_table_row.find(\"a\")\n",
    "        if si_batting_anchor_tag:\n",
    "            \n",
    "            # Get the href attribute from the anchor tag\n",
    "            si_batting_href = si_batting_anchor_tag[\"href\"]\n",
    "            # put the link in a list\n",
    "            si_batting_links.append(URL_to_added+si_batting_href)\n",
    "            # Print the href\n",
    "            #print(si_batting_links)\n",
    "        else:\n",
    "            continue\n",
    "#         print(table_row.text)\n",
    "    for si_bowling_table_row in si_bowling_table_rows:\n",
    "        # Find the anchor tag within the table row\n",
    "        si_bowling_anchor_tag = si_bowling_table_row.find(\"a\")\n",
    "        if si_bowling_anchor_tag:\n",
    "            \n",
    "            # Get the href attribute from the anchor tag\n",
    "            si_bowling_href = si_bowling_anchor_tag[\"href\"]\n",
    "            # put the link in a list\n",
    "            si_bowling_links.append(URL_to_added+si_bowling_href)\n",
    "            # Print the href\n",
    "            #print(si_bowling_links)\n",
    "        else:\n",
    "            continue\n",
    "#         print(table_row.text)\n",
    "               \n",
    "    i +=1\n",
    "# Print the href\n",
    "# print(fi_batting_links)\n",
    "   \n",
    "# fi and si links\n",
    "# convert the list into a df with the column name links\n",
    "fi_batting_links_df = pd.DataFrame({'Links': fi_batting_links})\n",
    "fi_bowling_links_df = pd.DataFrame({'Links': fi_bowling_links})\n",
    "si_batting_links_df = pd.DataFrame({'Links': si_batting_links})\n",
    "si_bowling_links_df = pd.DataFrame({'Links': si_bowling_links})\n",
    "\n",
    "\n",
    "# concatenate all the players links into a single df\n",
    "combined_df = pd.concat([fi_batting_links_df, fi_bowling_links_df,si_batting_links_df, si_bowling_links_df], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dadd60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the complete df:     (1199, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(213, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will drop the duplicate columns in the links table as captured above\n",
    "\n",
    "print('the shape of the complete df:    ',combined_df.shape)\n",
    "\n",
    "player_link_df = combined_df.drop_duplicates()\n",
    "player_link_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50d3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first row of the above df\n",
    "# open the link\n",
    "# get the player details in a df \n",
    "# the below extraxts the first table in a page and prints out the results\n",
    "# this does not consider the number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d78584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the player_name, player_country\n",
    "def player_name_country(soup):\n",
    "    player_name = soup.find('h2', class_='ds-text-title-xs ds-font-bold ds-text-typo').text\n",
    "\n",
    "    \n",
    "    meta_tag = soup.find('meta', attrs={'name': 'title'})\n",
    "    content_text = meta_tag.get('content')\n",
    "    segments1 = content_text.split('|')  # Split the string by the '|' delimiter\n",
    "    segments2 = content_text.split(' ')\n",
    "    player_country = segments2[-5].strip()  # Access the last but the 5th element and remove any leading/trailing whitespaces\n",
    "\n",
    "    return player_name, player_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48acfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bat_style(soup):\n",
    "    # Access the 'div' element with class 'container'\n",
    "    container_div = soup.find('div', class_='ds-grid lg:ds-grid-cols-3 ds-grid-cols-2 ds-gap-4 ds-mb-8')\n",
    "\n",
    "\n",
    "    # Access the fifth div under the parent div\n",
    "    fifth_div = container_div.find_all('div')[3]\n",
    "\n",
    "    span_text = fifth_div.find('span', class_ = 'ds-text-title-s ds-font-bold ds-text-typo')\n",
    "\n",
    "    # Extract and print the text content of the fifth div\n",
    "    # print(\"Fifth Div:\", fifth_div.text)\n",
    "#     print(\"span text:   \", span_text.text)\n",
    "    return span_text.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4095a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowl_style(soup):\n",
    "    # Access the 'div' element with class 'container'\n",
    "    container_div = soup.find('div', class_='ds-grid lg:ds-grid-cols-3 ds-grid-cols-2 ds-gap-4 ds-mb-8')\n",
    "\n",
    "\n",
    "    # Access the fifth div under the parent div\n",
    "    fifth_div = container_div.find_all('div')[4]\n",
    "\n",
    "    span_text = fifth_div.find('span', class_ = 'ds-text-title-s ds-font-bold ds-text-typo')\n",
    "\n",
    "    # Extract and print the text content of the fifth div\n",
    "    # print(\"Fifth Div:\", fifth_div.text)\n",
    "#     print(\"span text:   \", span_text.text)\n",
    "    return span_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3253360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playing_role(soup):\n",
    "    # Access the 'div' element with class 'container'\n",
    "    container_div = soup.find('div', class_='ds-grid lg:ds-grid-cols-3 ds-grid-cols-2 ds-gap-4 ds-mb-8')\n",
    "\n",
    "   \n",
    "    try:\n",
    "    # Your code that may raise an IndexError\n",
    "        fifth_div = container_div.find_all('div')[5]\n",
    "        span_text = fifth_div.find_all('p')[1]\n",
    "        role = span_text.text\n",
    "    except IndexError:\n",
    "    # Handle the IndexError by assigning \"No Data found\" to the variable\n",
    "        fifth_div = \"NotAvailable\"\n",
    "        role = fifth_div\n",
    "\n",
    "    return role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5f061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below gets the data of batting and bowling\n",
    "# first find the length of the links table above. This can be used as a counter in the loop\n",
    "# have added the player, batting, bowling style and country name to which the player belongs to the table which has stats\n",
    "\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "# from lxml import etree\n",
    "\n",
    "\n",
    "# temp_df = pd.DataFrame()\n",
    "combined_batting_fielding_stats_df = pd.DataFrame()\n",
    "combined_bowling_stats_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# counter for the while loop and will iterate limit is the length of the links table\n",
    "i = 0\n",
    "l_player_link_df = len(player_link_df)\n",
    "# l_player_link_df = 30\n",
    "\n",
    "# the while loop runs for the length of the list of players in the tournment\n",
    "while(i<l_player_link_df):\n",
    "#     print('count of i: ',i)\n",
    "    \n",
    "# temp df to store the batting and bowling stats of a player - everytime make it an empty df\n",
    "    batting_df = pd.DataFrame()\n",
    "    bowling_df = pd.DataFrame()\n",
    "    \n",
    "    player_URL = player_link_df.iloc[i,0]\n",
    "\n",
    "    header = ({'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36', 'Accept-Language' : 'eng-US'\n",
    "                })\n",
    "\n",
    "    webpage = requests.get(player_URL, headers=header)\n",
    "    soup_individual_players = BeautifulSoup(webpage.content, 'html.parser')\n",
    "    \n",
    "# select the first table - this will give either batting or bowling stats\n",
    "    first_table = soup_individual_players.find_all('table')[0]\n",
    "    \n",
    "# if table is present\n",
    "    if first_table:\n",
    "        \n",
    "# find the number of rows to decide whether it gives batting or bowling stats\n",
    "        col_first_table = first_table.find_all('th')\n",
    "        col_count_first_table = len(col_first_table)\n",
    "        \n",
    "        \n",
    "# if the columns are 14 then the table is gives bowling stas\n",
    "        if (col_count_first_table == 14):\n",
    "            bowling_df = pd.read_html(str(first_table), header=0)[0]\n",
    "            bowling_df.reset_index(drop=True, inplace=True)\n",
    "# call the method to retrieve the the player and country name\n",
    "            player_name, player_country = player_name_country(soup_individual_players)\n",
    "    \n",
    "# call the method to get the bowling style\n",
    "            batsman_bowling_style = bowl_style(soup_individual_players)\n",
    "# call the method to get the Playing Role\n",
    "            batsman_playing_role = playing_role(soup_individual_players)\n",
    "#             print(player_name)\n",
    "# add the details to the table read\n",
    "            bowling_df['player_name'] = player_name\n",
    "            bowling_df['player_country'] = player_country\n",
    "            bowling_df['batsman_bowling_style'] = batsman_bowling_style\n",
    "            bowling_df['batsman_playing_role'] = batsman_playing_role\n",
    "\n",
    "# if the columns are 15 then the table is gives bowling stas\n",
    "        elif(col_count_first_table == 15):\n",
    "            \n",
    "            batting_df = pd.read_html(str(first_table), header=0)[0]\n",
    "            batting_df.reset_index(drop=True, inplace=True)\n",
    "# call the method to retrieve the the player and country name\n",
    "            player_name, player_country = player_name_country(soup_individual_players)\n",
    "    \n",
    "# call the method to get the batting style\n",
    "            batsman_batting_style = bat_style(soup_individual_players)\n",
    "#             print(player_name)\n",
    "        \n",
    "# call the method to get the Playing Role\n",
    "            batsman_playing_role = playing_role(soup_individual_players)\n",
    "\n",
    "# add the details to the table read\n",
    "            batting_df['player_name'] = player_name\n",
    "            batting_df['player_country'] = player_country\n",
    "            batting_df['batsman_batting_style'] = batsman_batting_style\n",
    "            batting_df['batsman_playing_role'] = batsman_playing_role\n",
    "\n",
    "# select the second table\n",
    "    second_table = soup_individual_players.find_all('table')[1]\n",
    "\n",
    "    if second_table:\n",
    "\n",
    "        col_second_table = second_table.find_all('th')\n",
    "        col_count_second_table = len(col_second_table)\n",
    "        \n",
    "# if the columns are 14 then the table is gives bowling stats\n",
    "        if (col_count_second_table == 14):\n",
    "            bowling_df = pd.read_html(str(second_table), header=0)[0]\n",
    "            bowling_df.reset_index(drop=True, inplace=True)\n",
    "#             call the method to retrieve the the player and country name\n",
    "            player_name, player_country = player_name_country(soup_individual_players)\\\n",
    "# call the menthod to get the bowling style pf the player\n",
    "            batsman_bowling_style = bowl_style(soup_individual_players)\n",
    "# call the method to get the Playing Role\n",
    "            batsman_playing_role = playing_role(soup_individual_players)\n",
    "#             print(player_name)\n",
    "# add the details to the table read\n",
    "            bowling_df['player_name'] = player_name\n",
    "            bowling_df['player_country'] = player_country\n",
    "            bowling_df['batsman_bowling_style'] = batsman_bowling_style\n",
    "            bowling_df['batsman_playing_role'] = batsman_playing_role\n",
    "\n",
    "# if the columns are 15 then the table is gives bowling stats\n",
    "        elif(col_count_second_table == 15):\n",
    "\n",
    "            batting_df = pd.read_html(str(second_table), header=0)[0]\n",
    "            batting_df.reset_index(drop=True, inplace=True)\n",
    "# call the method to retrieve the the player, country name and batsman_batting_style\n",
    "            player_name, player_country = player_name_country(soup_individual_players)\n",
    "            batsman_batting_style = bat_style(soup_individual_players)\n",
    "#             print(player_name)\n",
    "# call the method to get the Playing Role\n",
    "            batsman_playing_role = playing_role(soup_individual_players)\n",
    "\n",
    "# add the details to the table read\n",
    "            batting_df['player_name'] = player_name\n",
    "            batting_df['player_country'] = player_country\n",
    "            batting_df['batsman_batting_style'] = batsman_batting_style\n",
    "            batting_df['batsman_playing_role'] = batsman_playing_role\n",
    "\n",
    "# add the temp df and combined_batting_fielding_stats_df everytime a player details are read\n",
    "    combined_batting_fielding_stats_df = pd.concat([combined_batting_fielding_stats_df, batting_df], ignore_index=True)\n",
    "    combined_bowling_stats_df = pd.concat([combined_bowling_stats_df, bowling_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    \n",
    "    i +=1\n",
    "    \n",
    "# print(combined_batting_fielding_stats_df.head())\n",
    "# print(combined_bowling_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feae3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the combined_batting_fielding_stats_df and combined_bowling_stats_df to a csv\n",
    "combined_batting_fielding_stats_df.to_csv('all_players_batting_fielding_stats_df.csv', index=False)  # Set index to False to exclude row numbers in the output\n",
    "combined_bowling_stats_df.to_csv('all_players_bowling_stats_df.csv', index=False)  # Set index to False to exclude row numbers in the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc7fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames based on 'player_name' and 'player_country'\n",
    "merged_df = pd.merge(combined_batting_fielding_stats_df, combined_bowling_stats_df, on=['player_name', 'player_country'], how='outer')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc5e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Format_x', 'Mat_x', 'Inns_x', 'NO', 'Runs_x', 'HS', 'Ave_x', 'BF',\n",
      "       'SR_x', '100s', '50s', '4s', '6s', 'Ct', 'St', 'player_name',\n",
      "       'player_country', 'batsman_batting_style', 'batsman_playing_role_x',\n",
      "       'Format_y', 'Mat_y', 'Inns_y', 'Balls', 'Runs_y', 'Wkts', 'BBI', 'BBM',\n",
      "       'Ave_y', 'Econ', 'SR_y', '4w', '5w', '10w', 'batsman_bowling_style',\n",
      "       'batsman_playing_role_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279dd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops not reqiored columns\n",
    "merged_df = merged_df.drop(['Format_x', 'Mat_x', 'Inns_x', 'NO', 'Runs_x', 'HS', 'Ave_x', 'BF',\n",
    "       'SR_x', '100s', '50s', '4s', '6s', 'Ct', 'St', 'Format_y', 'Mat_y',\n",
    "       'Inns_y', 'Balls', 'Runs_y', 'Wkts', 'BBI', 'BBM', 'Ave_y', 'Econ',\n",
    "       'SR_y', '4w', '5w', '10w',], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "835ac02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gets the player_brief_info_df\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "# merged_df.shape\n",
    "merged_df.to_csv('player_brief_info_df.csv')\n",
    "# print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ce7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
